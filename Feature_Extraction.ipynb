{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5cxe_5lJOPAm"
   },
   "outputs": [],
   "source": [
    "#importing all the modules needed fo running the script \n",
    "import os \n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import scipy.io.wavfile as wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "kjFYsjtLClNK",
    "outputId": "33ef9fc3-80e5-4b1b-a15c-a71868dc6d65"
   },
   "outputs": [],
   "source": [
    "# DATASET LOADING PARAMETERS\n",
    "case = 1\n",
    "# 'dev' - development or 'eval' - evaluation dataset, or both. \n",
    "process_str = 'dev, eval'\n",
    "\n",
    "# 'dev' - development or 'eval' - evaluation dataset\n",
    "mode='eval'\n",
    "# 'foa' - ambisonic or 'mic' - microphone signals                                               \n",
    "dataset='foa'    \n",
    "\n",
    "   \n",
    "dataset_aug = False if dataset == 'mic' else True\n",
    "\n",
    "\n",
    "base_dir = 'Base directory'\n",
    "#defining cross-validation split\n",
    "if mode == 'dev':\n",
    "  train_splits = [3, 4, 5, 6]\n",
    "elif mode == 'eval':\n",
    "  train_splits = [2, 3, 4, 5, 6]\n",
    "\n",
    "#how many new files we want to create from the original one.\n",
    "data_augmentation_nb = 2\n",
    "\n",
    "\n",
    "dataset_dir = base_dir + 'Dataset'\n",
    "\n",
    "    \n",
    "feat_label_dir= os.path.join(dataset_dir, 'feat_label-AR')       \n",
    "\n",
    "image_dir = os.path.join(base_dir, 'images') \n",
    "\n",
    "#pattern rotation to consider for data augmentation. \n",
    "\n",
    "rotation_pattern = 15\n",
    "                                                                                                                                                                                      \n",
    "#FEATURE PARAMS\n",
    "fs=24000\n",
    "hop_len_s=0.02\n",
    "label_hop_len_s=0.1\n",
    "max_audio_len_s=60\n",
    "nb_mel_bins=64            \n",
    "\n",
    "unique_classes = {\n",
    "            'alarm': 0,\n",
    "            'baby': 1,\n",
    "            'crash': 2,\n",
    "            'dog': 3,\n",
    "            'engine': 4,\n",
    "            'female_scream': 5,\n",
    "            'female_speech': 6,\n",
    "            'fire': 7,\n",
    "            'footsteps': 8,\n",
    "            'knock': 9,\n",
    "            'male_scream': 10,\n",
    "            'male_speech': 11,\n",
    "            'phone': 12,\n",
    "            'piano': 13\n",
    "        }\n",
    "\n",
    "\n",
    "    # ########### User defined parameters ##############\n",
    "    \n",
    "if case == 1:\n",
    "  print(\"USING DEFAULT PARAMETERS\\n\")\n",
    "\n",
    "elif case == 2:\n",
    "  mode = 'dev'\n",
    "  dataset = 'mic'\n",
    "\n",
    "elif case == 3:\n",
    "   mode = 'eval'\n",
    "   dataset = 'mic'\n",
    "\n",
    "elif case == 4:\n",
    "    mode = 'dev'\n",
    "    dataset = 'foa'\n",
    "\n",
    "elif case == 5:\n",
    "    mode = 'eval'\n",
    "    dataset = 'foa'\n",
    "\n",
    "elif case == 999:\n",
    "      print(\"QUICK TEST MODE\\n\")\n",
    "      quick_test = True\n",
    "      epochs_per_fit = 1\n",
    "\n",
    "else:\n",
    "    print('ERROR: unknown argument {}'.format(case))\n",
    "    exit()\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HsywcYlYOU33"
   },
   "outputs": [],
   "source": [
    "#function to create a new folder in case it does not exist yet. \n",
    "def create_folder(folder_name):\n",
    "    \n",
    "    if not os.path.exists(folder_name):\n",
    "        print('{} folder does not exist, creating it.'.format(folder_name))\n",
    "        os.makedirs(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jlK4gp2tP0UG"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import scipy.io.wavfile as wav\n",
    "\n",
    "\n",
    "def apply_data_augmentation(audio):\n",
    "    \n",
    "    \n",
    "    #selecting the a random pattern between the 15 implemented\n",
    "    pattern = random.randrange(rotation_pattern) # original case not considered for augmentation\n",
    "    print(\"Data augmentation pattern {}\".format(pattern))\n",
    "        \n",
    "    audio_aug = np.zeros(audio.shape)\n",
    "\n",
    "    w = audio[:, 0]\n",
    "    y = audio[:, 1]\n",
    "    z = audio[:, 2]\n",
    "    x = audio[:, 3]\n",
    "    \n",
    "    # w channel never change \n",
    "    audio_aug[:, 0] = w\n",
    "\n",
    "    # the 15 pattern rotations and reflection\n",
    "    if (pattern == 0):\n",
    "        #print('Φ - pi/2')\n",
    "        audio_aug[:, 1] = -x\n",
    "        audio_aug[:, 3] = y\n",
    "        audio_aug[:, 2] = z  \n",
    "    elif (pattern == 1):\n",
    "        #print('Φ - pi/2, -θ')\n",
    "        audio_aug[:, 1] = -x\n",
    "        audio_aug[:, 3] = y\n",
    "        audio_aug[:, 2] = -z\n",
    "    \n",
    "    elif (pattern == 2):\n",
    "        #print('Φ, -θ')\n",
    "        audio_aug[:, 1] = y\n",
    "        audio_aug[:, 3] = x\n",
    "        audio_aug[:, 2] = -z\n",
    "    \n",
    "    elif (pattern == 3):\n",
    "        #print('Φ + pi/2')\n",
    "        audio_aug[:, 1] = x\n",
    "        audio_aug[:, 3] = -y\n",
    "        audio_aug[:, 2] = z    \n",
    "    elif (pattern == 4):    \n",
    "        #print('Φ + pi/2, -θ')\n",
    "        audio_aug[:, 1] = x\n",
    "        audio_aug[:, 3] = -y\n",
    "        audio_aug[:, 2] = -z\n",
    "        \n",
    "    elif (pattern == 5):\n",
    "        #print('-Φ - pi/2')\n",
    "        audio_aug[:, 1] = x\n",
    "        audio_aug[:, 3] = -y\n",
    "        audio_aug[:, 2] = z\n",
    "    elif (pattern == 6):\n",
    "        #print('-Φ - pi/2, -θ')\n",
    "        audio_aug[:, 1] = -x\n",
    "        audio_aug[:, 3] = -y\n",
    "        audio_aug[:, 2] = -z\n",
    "    \n",
    "    elif (pattern == 7):\n",
    "        #print('-Φ')\n",
    "        audio_aug[:, 1] = -y\n",
    "        audio_aug[:, 3] = x\n",
    "        audio_aug[:, 2] = z  \n",
    "    elif (pattern == 8):\n",
    "        \n",
    "        \n",
    "        audio_aug[:, 1] = -y\n",
    "        audio_aug[:, 3] = x\n",
    "        audio_aug[:, 2] = -z\n",
    "    \n",
    "    elif (pattern == 9):\n",
    "        \n",
    "        audio_aug[:, 1] = x\n",
    "        audio_aug[:, 3] = y\n",
    "        audio_aug[:, 2] = z  \n",
    "    elif (pattern == 10):\n",
    "       \n",
    "        audio_aug[:, 1] = x\n",
    "        audio_aug[:, 3] = y\n",
    "        audio_aug[:, 2] = -z\n",
    "    \n",
    "    elif (pattern == 11):\n",
    "       \n",
    "        audio_aug[:, 1] = y\n",
    "        audio_aug[:, 3] = -x\n",
    "        audio_aug[:, 2] = z      \n",
    "    elif (pattern == 12):\n",
    "        \n",
    "        audio_aug[:, 1] = y\n",
    "        audio_aug[:, 3] = -x\n",
    "        audio_aug[:, 2] = -z\n",
    "        \n",
    "    elif (pattern == 13):\n",
    "       \n",
    "        audio_aug[:, 1] = -x\n",
    "        audio_aug[:, 3] = -y\n",
    "        audio_aug[:, 2] = z    \n",
    "    elif (pattern == 14):\n",
    "        \n",
    "        audio_aug[:, 1] = -x\n",
    "        audio_aug[:, 3] = -y\n",
    "        audio_aug[:, 2] = -z  \n",
    "    \n",
    "    else:\n",
    "        print(\"Wrong pattern selection\")\n",
    "        \n",
    "    return audio_aug, pattern\n",
    "\n",
    "\n",
    "def label_rotation(label, pattern):\n",
    "\n",
    "  \n",
    "\n",
    "  label_aug = np.zeros(len(label))\n",
    "    # w channel never change \n",
    "  label_aug[0] = label[0]\n",
    "\n",
    "  if (pattern == 0):\n",
    "        #print('Φ - pi/2')\n",
    "        label_aug[1] = label[2]\n",
    "        label_aug[2] = -label[1]\n",
    "        label_aug[3] = label[3]\n",
    "  elif (pattern == 1):\n",
    "        #print('Φ - pi/2, -θ')\n",
    "        label_aug[1] = label[2]\n",
    "        label_aug[2] = -label[1]\n",
    "        label_aug[3] = -label[3]\n",
    "    \n",
    "  elif (pattern == 2):\n",
    "        #print('Φ, -θ')\n",
    "        label_aug[1] = label[1]\n",
    "        label_aug[2] = label[2]\n",
    "        label_aug[3] = -label[3]\n",
    "    \n",
    "  elif (pattern == 3):\n",
    "        #print('Φ + pi/2')\n",
    "        label_aug[1] = -label[2]\n",
    "        label_aug[2] = label[1]\n",
    "        label_aug[3] = label[3]\n",
    "  elif (pattern == 4):    \n",
    "        #print('Φ + pi/2, -θ')\n",
    "        label_aug[1] = -label[2]\n",
    "        label_aug[2] = label[1]\n",
    "        label_aug[3] = -label[3]\n",
    "        \n",
    "  elif (pattern == 5):\n",
    "        #print('-Φ - pi/2')\n",
    "        label_aug[1] = -label[2]\n",
    "        label_aug[2] = label[1]\n",
    "        label_aug[3] = label[3]\n",
    "  elif (pattern == 6):\n",
    "        #print('-Φ - pi/2, -θ')\n",
    "        label_aug[1] = -label[2]\n",
    "        label_aug[2] = -label[1]\n",
    "        label_aug[3] = -label[3]\n",
    "    \n",
    "  elif (pattern == 7):\n",
    "        #print('-Φ')\n",
    "        label_aug[1] = label[1]\n",
    "        label_aug[2] = -label[2]\n",
    "        label_aug[3] = label[3]\n",
    "  elif (pattern == 8):\n",
    "        # - azimuth - pi/2 - elevation\n",
    "        #print('-Φ, -θ')\n",
    "        label_aug[1] = label[1]\n",
    "        label_aug[2] = -label[2]\n",
    "        label_aug[3] = -label[3]\n",
    "    \n",
    "  elif (pattern == 9):\n",
    "        #print('-Φ + pi/2')\n",
    "        label_aug[1] = label[2]\n",
    "        label_aug[2] = label[1]\n",
    "        label_aug[3] = label[3]\n",
    "  elif (pattern == 10):\n",
    "        #print('-Φ + pi/2, -θ')\n",
    "        label_aug[1] = label[2]\n",
    "        label_aug[2] = label[1]\n",
    "        label_aug[3] = -label[3]\n",
    "    \n",
    "  elif (pattern == 11):\n",
    "        #print('-Φ + pi')\n",
    "        label_aug[1] = -label[1]\n",
    "        label_aug[2] = label[2]\n",
    "        label_aug[3] = label[3]     \n",
    "  elif (pattern == 12):\n",
    "        # azimuth + pi/2 - elevation\n",
    "        #print('-Φ + pi, -θ')\n",
    "        label_aug[1] = -label[1]\n",
    "        label_aug[2] = label[2]\n",
    "        label_aug[3] = -label[3]\n",
    "        \n",
    "  elif (pattern == 13):\n",
    "        #print('Φ + pi')\n",
    "        label_aug[1] = -label[2]\n",
    "        label_aug[2] = -label[1]\n",
    "        label_aug[3] = label[3]\n",
    "  elif (pattern == 14):\n",
    "        #print('Φ + pi, -θ')\n",
    "        label_aug[1] = -label[2]\n",
    "        label_aug[2] = -label[1]\n",
    "        label_aug[3] = -label[3]\n",
    "    \n",
    "  else:\n",
    "        print(\"Wrong pattern selection\")\n",
    "        \n",
    "  return label_aug\n",
    "\n",
    "def label_augmentation(label_dir, pattern):\n",
    "\n",
    "    #print(\"Label augmentation pattern {}\".format(pattern))\n",
    "    \n",
    "    \n",
    "\n",
    "    label_aug_dict = {}\n",
    "    for frame_cnt in label_dir.keys():\n",
    "        if frame_cnt not in label_aug_dict:\n",
    "            label_aug_dict[frame_cnt] = []\n",
    "            for tmp_val in label_dir[frame_cnt]:\n",
    "                aug_tmp_value = label_rotation(tmp_val, pattern)\n",
    "                label_aug_dict[frame_cnt].append(aug_tmp_value)\n",
    "    return label_aug_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "1vfLkOnyCczy",
    "outputId": "1f478178-daf5-480e-e419-7fa64a311ee6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "1vfLkOnyCczy",
    "outputId": "1f478178-daf5-480e-e419-7fa64a311ee6"
   },
   "outputs": [],
   "source": [
    "# Contains routines for labels creation, features extraction and normalization\n",
    "from sklearn import preprocessing\n",
    "import joblib\n",
    "import math\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "\n",
    "def nCr(n, r):\n",
    "    return math.factorial(n) // math.factorial(r) // math.factorial(n-r)\n",
    "\n",
    "\n",
    "class FeatureClass:\n",
    "    def __init__(self, is_eval=False):\n",
    "        \n",
    "\n",
    "        # Input directories\n",
    "        self._feat_label_dir = feat_label_dir\n",
    "        self._dataset_dir = dataset_dir\n",
    "        self._dataset_combination = '{}_{}'.format(dataset, 'eval' if is_eval else 'dev')\n",
    "        \n",
    "        self._aud_dir = os.path.join(self._dataset_dir, self._dataset_combination)\n",
    "        self._desc_dir = None if is_eval else os.path.join(self._dataset_dir, \"metadata_dev\")\n",
    "\n",
    "        # Output directories\n",
    "        self._label_dir = None\n",
    "        self._feat_dir = None\n",
    "        self._feat_dir_norm = None\n",
    "\n",
    "        # Local parameters\n",
    "        self._is_eval = is_eval\n",
    "\n",
    "        self._fs = fs\n",
    "        self._hop_len_s = hop_len_s\n",
    "        self._hop_len = int(self._fs * self._hop_len_s)\n",
    "\n",
    "        self._label_hop_len_s = label_hop_len_s\n",
    "        self._label_hop_len = int(self._fs * self._label_hop_len_s)\n",
    "        self._label_frame_res = self._fs / float(self._label_hop_len)\n",
    "        self._nb_label_frames_1s = int(self._label_frame_res)\n",
    "\n",
    "        self._win_len = 2 * self._hop_len\n",
    "        self._nfft = self._next_greater_power_of_2(self._win_len)\n",
    "        self._nb_mel_bins = nb_mel_bins\n",
    "        self._mel_wts = librosa.filters.mel(sr=self._fs, n_fft=self._nfft, n_mels=self._nb_mel_bins).T\n",
    "\n",
    "        self._dataset = dataset\n",
    "        self._eps = 1e-8\n",
    "        self._nb_channels = 4\n",
    "\n",
    "        # Sound event classes dictionary\n",
    "        self._unique_classes = unique_classes\n",
    "        self._audio_max_len_samples = max_audio_len_s * self._fs \n",
    "\n",
    "        self._max_feat_frames = int(np.ceil(self._audio_max_len_samples / float(self._hop_len)))\n",
    "        self._max_label_frames = int(np.ceil(self._audio_max_len_samples / float(self._label_hop_len)))\n",
    "\n",
    "    def _load_audio(self, audio_path):\n",
    "\n",
    "        fs, audio = wav.read(audio_path)\n",
    "        audio = audio[:, :self._nb_channels] / 32768.0 + self._eps\n",
    "        if audio.shape[0] < self._audio_max_len_samples:\n",
    "            zero_pad = np.random.rand(self._audio_max_len_samples - audio.shape[0], audio.shape[1])*self._eps\n",
    "            audio = np.vstack((audio, zero_pad))\n",
    "        elif audio.shape[0] > self._audio_max_len_samples:\n",
    "            audio = audio[:self._audio_max_len_samples, :]\n",
    "        return audio, fs\n",
    "\n",
    "    # INPUT FEATURES\n",
    "    @staticmethod\n",
    "    def _next_greater_power_of_2(x):\n",
    "        return 2 ** (x - 1).bit_length()\n",
    "\n",
    "    def _spectrogram(self, audio_input):\n",
    "      \n",
    "      _nb_ch = audio_input.shape[1]\n",
    "      nb_bins = self._nfft // 2\n",
    "      spectra = np.zeros((self._max_feat_frames, nb_bins + 1, _nb_ch), dtype=complex)\n",
    "      for ch_cnt in range(_nb_ch):\n",
    "          stft_ch = librosa.core.stft(np.asfortranarray(audio_input[:, ch_cnt]), n_fft=self._nfft, hop_length=self._hop_len,\n",
    "                                        win_length=self._win_len, window='hann')\n",
    "          spectra[:, :, ch_cnt] = stft_ch[:, :self._max_feat_frames].T\n",
    "      return spectra\n",
    "\n",
    "    def _get_mel_spectrogram(self, linear_spectra_list):\n",
    "        \n",
    "        \n",
    "        mel_feat_list = []\n",
    "        for spec in range(len(linear_spectra_list)):\n",
    "            linear_spectra = linear_spectra_list[spec]\n",
    "            mel_feat = np.zeros((linear_spectra.shape[0], self._nb_mel_bins, linear_spectra.shape[-1]))\n",
    "            for ch_cnt in range(linear_spectra.shape[-1]):\n",
    "                mag_spectra = np.abs(linear_spectra[:, :, ch_cnt])**2\n",
    "                mel_spectra = np.dot(mag_spectra, self._mel_wts)\n",
    "                log_mel_spectra = librosa.power_to_db(mel_spectra)\n",
    "                mel_feat[:, :, ch_cnt] = log_mel_spectra\n",
    "            mel_feat = mel_feat.reshape((linear_spectra.shape[0], self._nb_mel_bins * linear_spectra.shape[-1]))\n",
    "            mel_feat_list.append(mel_feat)\n",
    "\n",
    "        return mel_feat_list\n",
    "\n",
    "    def _get_foa_intensity_vectors(self, linear_spectra_list):\n",
    "       \n",
    "        foa_iv_list = []\n",
    "        for spec in range(len(linear_spectra_list)):\n",
    "            linear_spectra = linear_spectra_list[spec]\n",
    "            IVx = np.real(np.conj(linear_spectra[:, :, 0]) * linear_spectra[:, :, 1])\n",
    "            IVy = np.real(np.conj(linear_spectra[:, :, 0]) * linear_spectra[:, :, 2])\n",
    "            IVz = np.real(np.conj(linear_spectra[:, :, 0]) * linear_spectra[:, :, 3])\n",
    "\n",
    "            normal = np.sqrt(IVx ** 2 + IVy ** 2 + IVz ** 2) + self._eps\n",
    "            IVx = np.dot(IVx / normal, self._mel_wts)\n",
    "            IVy = np.dot(IVy / normal, self._mel_wts)\n",
    "            IVz = np.dot(IVz / normal, self._mel_wts)\n",
    "\n",
    "            # we are doing the following instead of simply concatenating to keep the processing similar to mel_spec and gcc\n",
    "            foa_iv = np.dstack((IVx, IVy, IVz))\n",
    "            foa_iv = foa_iv.reshape((linear_spectra.shape[0], self._nb_mel_bins * 3))\n",
    "            if np.isnan(foa_iv).any():\n",
    "                print('Feature extraction is generating nan outputs')\n",
    "                exit()\n",
    "            foa_iv_list.append(foa_iv)\n",
    "\n",
    "        return foa_iv_list\n",
    "\n",
    "\n",
    "\n",
    "    def _get_gcc(self, linear_spectra_list):\n",
    "        \n",
    "        gcc_feat_list = []\n",
    "        for linear_spectra in linear_spectra_list:\n",
    "            gcc_channels = nCr(linear_spectra.shape[-1], 2)\n",
    "            gcc_feat = np.zeros((linear_spectra.shape[0], self._nb_mel_bins, gcc_channels))\n",
    "            cnt = 0\n",
    "            for m in range(linear_spectra.shape[-1]):\n",
    "                for n in range(m+1, linear_spectra.shape[-1]):\n",
    "                    R = np.conj(linear_spectra[:, :, m]) * linear_spectra[:, :, n]\n",
    "                    cc = np.fft.irfft(np.exp(1.j*np.angle(R)))\n",
    "                    cc = np.concatenate((cc[:, -self._nb_mel_bins//2:], cc[:, :self._nb_mel_bins//2]), axis=-1)\n",
    "                    gcc_feat[:, :, cnt] = cc\n",
    "                    cnt += 1\n",
    "            gcc_feat = gcc_feat.reshape((linear_spectra.shape[0], self._nb_mel_bins*gcc_channels))\n",
    "            gcc_feat_list.append(gcc_feat)\n",
    "\n",
    "        return gcc_feat_list\n",
    "\n",
    "    def _get_spectrogram_for_file(self, audio_filename):\n",
    "        \n",
    "        list_spec = []\n",
    "        \n",
    "        if dataset == 'foa':\n",
    "          pattern = np.zeros(data_augmentation_nb, dtype=int)\n",
    "\n",
    "        audio_in, fs = self._load_audio(os.path.join(self._aud_dir, audio_filename))\n",
    "        audio_spec = self._spectrogram(audio_in)\n",
    "\n",
    "        list_spec.append(audio_spec)\n",
    "\n",
    "        if audio_filename[4] in train_splits and dataset == 'foa' and not self._is_eval:\n",
    "            for i in range(data_augmentation_nb):\n",
    "                audio_aug, pattern[i] = apply_data_augmentation(audio_in)\n",
    "                audio_spec_aug = self._spectrogram(audio_aug)\n",
    "                list_spec.append(audio_spec_aug)\n",
    "\n",
    "        if dataset == 'foa':\n",
    "          return list_spec, pattern\n",
    "        else:\n",
    "          return list_spec\n",
    "\n",
    "\n",
    "    # OUTPUT LABELS\n",
    "    def get_labels_for_file(self, _desc_file):\n",
    "        \n",
    "        se_label = np.zeros((self._max_label_frames, len(self._unique_classes)))\n",
    "        x_label = np.zeros((self._max_label_frames, len(self._unique_classes)))\n",
    "        y_label = np.zeros((self._max_label_frames, len(self._unique_classes)))\n",
    "        z_label = np.zeros((self._max_label_frames, len(self._unique_classes)))\n",
    "\n",
    "        for frame_ind, active_event_list in _desc_file.items():\n",
    "            if frame_ind < self._max_label_frames:\n",
    "                for active_event in active_event_list:\n",
    "                    se_label[frame_ind, active_event[0]] = 1\n",
    "                    x_label[frame_ind, active_event[0]] = active_event[1]\n",
    "                    y_label[frame_ind, active_event[0]] = active_event[2]\n",
    "                    z_label[frame_ind, active_event[0]] = active_event[3]\n",
    "\n",
    "        label_mat = np.concatenate((se_label, x_label, y_label, z_label), axis=1)\n",
    "        return label_mat\n",
    "\n",
    "    # ------------------------------- EXTRACT FEATURE AND PREPROCESS IT -------------------------------\n",
    "    def extract_all_feature(self):\n",
    "        \n",
    "        # setting up folders\n",
    "        self._feat_dir = self.get_unnormalized_feat_dir()\n",
    "        create_folder(self._feat_dir)\n",
    "\n",
    "        # extraction starts\n",
    "        print('Extracting spectrogram:')\n",
    "        print('\\t\\taud_dir {}\\n\\t\\tdesc_dir {}\\n\\t\\tfeat_dir {}'.format(\n",
    "            self._aud_dir, self._desc_dir, self._feat_dir))\n",
    "        for split in os.listdir(self._aud_dir):\n",
    "            print('Split: {}'.format(split))\n",
    "            for file_cnt, file_name in enumerate(os.listdir(os.path.join(self._aud_dir, split))):\n",
    "#             for file_cnt, file_name in enumerate(os.listdir(self._aud_dir)):\n",
    "                #save the pattern implemented for each file\n",
    "                if file_name != '.DS_Store':\n",
    "                    wav_filename = '{}.wav'.format(file_name.split('.')[0])\n",
    "                    if dataset == 'foa':\n",
    "                      # implementation of data augmnetation based on channel rotations\n",
    "                       \n",
    "                      spect, pattern = self._get_spectrogram_for_file(os.path.join(self._aud_dir, split, wav_filename))\n",
    "                    else:\n",
    "                      spect = self._get_spectrogram_for_file(os.path.join(self._aud_dir, split, wav_filename))\n",
    "\n",
    "                    #extract mel\n",
    "                    mel_spect = self._get_mel_spectrogram(spect)\n",
    "\n",
    "                    feat_list = []\n",
    "                    if self._dataset is 'foa':\n",
    "                        # extract intensity vectors\n",
    "                        foa_iv = self._get_foa_intensity_vectors(spect)\n",
    "                        for foa_index in range(len(foa_iv)):\n",
    "#                             plot figures\n",
    "                            \n",
    "#                             print(\"Plotting\")\n",
    "#                             plot.figure(figsize=(22, 5))\n",
    "\n",
    "#                             plot.subplot(211, xlabel='Time', ylabel='Frequency', title='mel-spect %s' % (foa_index)), \\\n",
    "#                             plot.imshow(mel_spect[foa_index].T)\n",
    "\n",
    "\n",
    "#                             plot.subplot(212, xlabel='Time', ylabel='Frequency', title='intensity vector'), \\\n",
    "#                             plot.imshow(foa_iv[foa_index].T)\n",
    "#                             plot.savefig(fname=image_dir + '%s_plot_%s.png' % (file_name.split('.')[0], foa_index), format='png')\n",
    "#                             plot.close()\n",
    "\n",
    "                            feat = np.concatenate((mel_spect[foa_index], foa_iv[foa_index]), axis=-1)\n",
    "                            feat_list.append(feat)\n",
    "\n",
    "                    elif self._dataset is 'mic':\n",
    "                        # extract gcc\n",
    "                        gcc = self._get_gcc(spect)\n",
    "                        for gcc_index in range(len(gcc)):\n",
    "\n",
    "                            # plot figures\n",
    "                            # print(\"Plotting\")\n",
    "                            #plot.figure(figsize=(22, 5))\n",
    "\n",
    "                            #plot.subplot(211, xlabel='Time', ylabel='Frequency', title='mel-spect %s' % (gcc_index))\n",
    "                            #plot.imshow(mel_spect[gcc_index].T)\n",
    "\n",
    "                            #plot.subplot(212, xlabel='Time', ylabel='Frequency', title='generilized cross corrrelation')\n",
    "                            #plot.imshow(gcc[gcc_index].T)\n",
    "                            #plot.savefig(fname=image_dir + '%s_plot_%s.png' % (file_name.split('.')[0], gcc_index),\n",
    "                             #            format='png')\n",
    "\n",
    "                            feat = np.concatenate((mel_spect[gcc_index], gcc[gcc_index]), axis=-1)\n",
    "                            feat_list.append(feat)\n",
    "                    else:\n",
    "                        print('ERROR: Unknown dataset format {}'.format(self._dataset))\n",
    "                        exit()\n",
    "\n",
    "                    if len(feat_list) != 0:\n",
    "                        for element in range(len(feat_list)):\n",
    "                            print('{}: {}, {}, {}'.format(file_cnt, file_name, feat_list[element].shape, element))\n",
    "                            if element == 0:\n",
    "                              #no need to change the label name \n",
    "                              np.save(os.path.join(self._feat_dir, '{}-{}.npy'.format(wav_filename.split('.')[0], element)), feat_list[element]) \n",
    "                            else:\n",
    "                              #augmented data\n",
    "                              np.save(os.path.join(self._feat_dir, '{}-{}-{}.npy'.format(wav_filename.split('.')[0], element, pattern[element-1])), feat_list[element])\n",
    "                              #creation of augmented data labels\n",
    "                              label_folder = self._desc_dir\n",
    "                              label_path = os.path.join(label_folder, wav_filename.replace('.wav', '.csv'))\n",
    "                              label_dir_polar = self.load_output_format_file(label_path)\n",
    "                              label_dir = self.convert_output_format_polar_to_cartesian(label_dir_polar)\n",
    "                              #make the same rotation for the label and save with the same name on the metadata folder \n",
    "                              label_aug_dict = label_augmentation(label_dir, pattern[element-1])\n",
    "                              label_aug_dict_pol = self.convert_output_format_cartesian_to_polar(label_aug_dict)\n",
    "                              output_file_path = os.path.join(label_folder, '{}-{}-{}.csv'.format(wav_filename.split('.')[0], element, pattern[element-1]))\n",
    "                              self.write_polar_file(output_file_path, label_aug_dict_pol)\n",
    "                          \n",
    "                      \n",
    "\n",
    "\n",
    "    def preprocess_features(self):\n",
    "        \n",
    "        # Setting up folders and filenames\n",
    "        self._feat_dir = self.get_unnormalized_feat_dir()\n",
    "        self._feat_dir_norm = self.get_normalized_feat_dir()\n",
    "        create_folder(self._feat_dir_norm)\n",
    "        normalized_features_wts_file = self.get_normalized_wts_file()\n",
    "        spec_scaler = None\n",
    "\n",
    "        # pre-processing starts\n",
    "        if self._is_eval:\n",
    "            spec_scaler = joblib.load(normalized_features_wts_file)\n",
    "            print('Normalized_features_wts_file: {}. Loaded.'.format(normalized_features_wts_file))\n",
    "\n",
    "        else:\n",
    "            #normalization using partial fit only on training dataset\n",
    "            print('Estimating weights for normalizing feature files:')\n",
    "            print('\\t\\tfeat_dir: {}'.format(self._feat_dir))\n",
    "\n",
    "            spec_scaler = preprocessing.StandardScaler()\n",
    "            for file_cnt, file_name in enumerate(os.listdir(self._feat_dir)):\n",
    "                print('{}: {}'.format(file_cnt, file_name))\n",
    "                feat_file = np.load(os.path.join(self._feat_dir, file_name))\n",
    "                spec_scaler.partial_fit(feat_file)\n",
    "                del feat_file\n",
    "            joblib.dump(\n",
    "                spec_scaler,\n",
    "                normalized_features_wts_file\n",
    "            )\n",
    "            print('Normalized_features_wts_file: {}. Saved.'.format(normalized_features_wts_file))\n",
    "\n",
    "        #transformign all the dataset\n",
    "        print('Normalizing feature files:')\n",
    "        print('\\t\\tfeat_dir_norm {}'.format(self._feat_dir_norm))\n",
    "        for file_cnt, file_name in enumerate(os.listdir(self._feat_dir)):\n",
    "            print('{}: {}'.format(file_cnt, file_name))\n",
    "            feat_file = np.load(os.path.join(self._feat_dir, file_name))\n",
    "            feat_file = spec_scaler.transform(feat_file)\n",
    "            np.save(\n",
    "                os.path.join(self._feat_dir_norm, file_name),\n",
    "                feat_file\n",
    "            )\n",
    "            del feat_file\n",
    "\n",
    "        print('normalized files written to {}'.format(self._feat_dir_norm))\n",
    "\n",
    "    # ------------------------------- EXTRACT LABELS AND PREPROCESS IT -------------------------------\n",
    "#     def extract_all_labels(self):\n",
    "#         \"\"\"\n",
    "#          The function properly extracts all the labels\n",
    "#         \"\"\"\n",
    "#         self._label_dir = self.get_label_dir()\n",
    "\n",
    "#         print('Extracting labels:')\n",
    "#         print('\\t\\taud_dir {}\\n\\t\\tdesc_dir {}\\n\\t\\tlabel_dir {}'.format(\n",
    "#             self._aud_dir, self._desc_dir, self._label_dir))\n",
    "#         create_folder(self._label_dir)\n",
    "#         for split in os.listdir(self._desc_dir):\n",
    "#             print('Split: {}'.format(split))\n",
    "#             for file_cnt, file_name in enumerate(os.listdir(os.path.join(self._desc_dir, split)):\n",
    "#                 print(file_name)\n",
    "#                 if len(file_name)!=26: #checking clean metadata files #TODO this is not required if the dataset is clean\n",
    "#                     continue\n",
    "#                 print(\"label >>\",file_name)\n",
    "#                 wav_filename = '{}.wav'.format(file_name.split('.')[0])\n",
    "#                 desc_file_polar = self.load_output_format_file(os.path.join(self._desc_dir, file_name))\n",
    "#                 desc_file = self.convert_output_format_polar_to_cartesian(desc_file_polar)\n",
    "#                 label_mat = self.get_labels_for_file(desc_file)\n",
    "#                 print('{}: {}, {}'.format(file_cnt, file_name, label_mat.shape))\n",
    "#                 np.save(os.path.join(self._label_dir, '{}.npy'.format(wav_filename.split('.')[0])), label_mat)\n",
    "\n",
    "\n",
    "\n",
    "    def extract_all_labels(self):\n",
    "            self._label_dir = self.get_label_dir()\n",
    "\n",
    "            print('Extracting labels:')\n",
    "            print('\\t\\taud_dir {}\\n\\t\\tdesc_dir {}\\n\\t\\tlabel_dir {}'.format(\n",
    "                self._aud_dir, self._desc_dir, self._label_dir))\n",
    "            create_folder(self._label_dir)\n",
    "            for split in os.listdir(self._desc_dir):\n",
    "                split_dir = os.path.join(self._desc_dir, split)\n",
    "                print('Split: {}'.format(split_dir))\n",
    "                \n",
    "                for file_cnt, file_name in enumerate(os.listdir(split_dir)):\n",
    "                    wav_filename = '{}.wav'.format(file_name.split('.')[0])\n",
    "                    \n",
    "                    desc_file_polar = self.load_output_format_file(os.path.join(os.path.join(self._desc_dir, split, file_name)))\n",
    "                    desc_file = self.convert_output_format_polar_to_cartesian(desc_file_polar)\n",
    "                    \n",
    "                    label_mat = self.get_labels_for_file(desc_file)\n",
    "                    print('\\t{}: {}, {}'.format(file_cnt, file_name, label_mat.shape))\n",
    "                    np.save(os.path.join(self._label_dir, '{}.npy'.format(wav_filename.split('.')[0])), label_mat)\n",
    "\n",
    "    # -------------------------------  DCASE OUTPUT  FORMAT FUNCTIONS -------------------------------\n",
    "    def load_output_format_file(self, _output_format_file):\n",
    "        \n",
    "        _output_dict = {}\n",
    "        _fid = open(_output_format_file, 'r')\n",
    "        # next(_fid)\n",
    "        for _line in _fid:\n",
    "            _words = _line.strip().split(',')\n",
    "            _frame_ind = _words[0]\n",
    "            try:\n",
    "                _frame_ind = int(_words[0])\n",
    "            except:\n",
    "                print (\"error\",_words[0])\n",
    "            if _words[0] not in _output_dict:\n",
    "                _output_dict[_frame_ind] = []\n",
    "            if len(_words) == 5: #read polar coordinates format, we ignore the track count \n",
    "                _output_dict[_frame_ind].append([int(_words[1]), float(_words[3]), float(_words[4]), int(_words[2])])\n",
    "            elif len(_words) == 6: # read Cartesian coordinates format, we ignore the track count\n",
    "                _output_dict[_frame_ind].append([int(_words[1]), float(_words[3]), float(_words[4]), float(_words[5]), int(_words[2])])\n",
    "        _fid.close()\n",
    "        return _output_dict\n",
    "\n",
    "\n",
    "    def write_output_format_file(self, _output_format_file, _output_format_dict):\n",
    "        \n",
    "        _fid = open(_output_format_file, 'w')\n",
    "        # _fid.write('{},{},{},{}\\n'.format('frame number with 20ms hop (int)', 'class index (int)', 'azimuth angle (int)', 'elevation angle (int)'))\n",
    "        for _frame_ind in _output_format_dict.keys():\n",
    "            for _value in _output_format_dict[_frame_ind]:\n",
    "                # Write Cartesian format output. Since baseline does not estimate track count we use a fixed value.\n",
    "                _fid.write('{},{},{},{},{},{}\\n'.format(int(_frame_ind), int(_value[0]), 0, float(_value[1]), float(_value[2]), float(_value[3])))\n",
    "        _fid.close()\n",
    "\n",
    "    def write_polar_file(self, output_file, output_format_dict):\n",
    "        \n",
    "        _fid = open(output_file, 'w')\n",
    "        # _fid.write('{},{},{},{}\\n'.format('frame number with 20ms hop (int)', 'class index (int)', 'azimuth angle (int)', 'elevation angle (int)'))\n",
    "        for _frame_ind in output_format_dict.keys():\n",
    "            for _value in output_format_dict[_frame_ind]:\n",
    "              # Write polar coordinates format output. Since baseline does not estimate track count we use a fixed value.\n",
    "                _fid.write('{},{},{},{},{}\\n'.format(int(_frame_ind), int(_value[0]), 0, int(_value[1]), int(_value[2])))\n",
    "    \n",
    "        _fid.close()\n",
    "\n",
    "    def segment_labels(self, _pred_dict, _max_frames):\n",
    "        \n",
    "        nb_blocks = int(np.ceil(_max_frames/float(self._nb_label_frames_1s)))\n",
    "        output_dict = {x: {} for x in range(nb_blocks)}\n",
    "        for frame_cnt in range(0, _max_frames, self._nb_label_frames_1s):\n",
    "\n",
    "            # Collect class-wise information for each block\n",
    "            # [class][frame] = <list of doa values>\n",
    "            # Data structure supports multi-instance occurence of same class\n",
    "            block_cnt = frame_cnt // self._nb_label_frames_1s\n",
    "            loc_dict = {}\n",
    "            for audio_frame in range(frame_cnt, frame_cnt+self._nb_label_frames_1s):\n",
    "                if audio_frame not in _pred_dict:\n",
    "                    continue\n",
    "                for value in _pred_dict[audio_frame]:\n",
    "                    if value[0] not in loc_dict:\n",
    "                        loc_dict[value[0]] = {}\n",
    "\n",
    "                    block_frame = audio_frame - frame_cnt\n",
    "                    if block_frame not in loc_dict[value[0]]:\n",
    "                        loc_dict[value[0]][block_frame] = []\n",
    "                    loc_dict[value[0]][block_frame].append(value[1:])\n",
    "\n",
    "            # Update the block wise details collected above in a global structure\n",
    "            for class_cnt in loc_dict:\n",
    "                if class_cnt not in output_dict[block_cnt]:\n",
    "                    output_dict[block_cnt][class_cnt] = []\n",
    "\n",
    "                keys = [k for k in loc_dict[class_cnt]]\n",
    "                values = [loc_dict[class_cnt][k] for k in loc_dict[class_cnt]]\n",
    "\n",
    "                output_dict[block_cnt][class_cnt].append([keys, values])\n",
    "\n",
    "        return output_dict\n",
    "\n",
    "    def regression_label_format_to_output_format(self, _sed_labels, _doa_labels):\n",
    "        \n",
    "        _nb_classes = len(self._unique_classes)\n",
    "        _is_polar = _doa_labels.shape[-1] == 2*_nb_classes\n",
    "        _azi_labels, _ele_labels = None, None\n",
    "        _x, _y, _z = None, None, None\n",
    "        if _is_polar:\n",
    "            _azi_labels = _doa_labels[:, :_nb_classes]\n",
    "            _ele_labels = _doa_labels[:, _nb_classes:]\n",
    "        else:\n",
    "            _x = _doa_labels[:, :_nb_classes]\n",
    "            _y = _doa_labels[:, _nb_classes:2*_nb_classes]\n",
    "            _z = _doa_labels[:, 2*_nb_classes:]\n",
    "\n",
    "        _output_dict = {}\n",
    "        for _frame_ind in range(_sed_labels.shape[0]):\n",
    "            _tmp_ind = np.where(_sed_labels[_frame_ind, :])\n",
    "            if len(_tmp_ind[0]):\n",
    "                _output_dict[_frame_ind] = []\n",
    "                for _tmp_class in _tmp_ind[0]:\n",
    "                    if _is_polar:\n",
    "                        _output_dict[_frame_ind].append([_tmp_class, _azi_labels[_frame_ind, _tmp_class], _ele_labels[_frame_ind, _tmp_class]])\n",
    "                    else:\n",
    "                        _output_dict[_frame_ind].append([_tmp_class, _x[_frame_ind, _tmp_class], _y[_frame_ind, _tmp_class], _z[_frame_ind, _tmp_class]])\n",
    "        return _output_dict\n",
    "\n",
    "    def convert_output_format_polar_to_cartesian(self, in_dict):\n",
    "        \n",
    "        out_dict = {}\n",
    "        for frame_cnt in in_dict.keys():\n",
    "            if frame_cnt not in out_dict:\n",
    "                out_dict[frame_cnt] = []\n",
    "                for tmp_val in in_dict[frame_cnt]:\n",
    "\n",
    "                    ele_rad = tmp_val[2]*np.pi/180.\n",
    "                    azi_rad = tmp_val[1]*np.pi/180\n",
    "\n",
    "                    tmp_label = np.cos(ele_rad)\n",
    "                    x = np.cos(azi_rad) * tmp_label\n",
    "                    y = np.sin(azi_rad) * tmp_label\n",
    "                    z = np.sin(ele_rad)\n",
    "                    out_dict[frame_cnt].append([tmp_val[0], x, y, z])\n",
    "        return out_dict\n",
    "\n",
    "    def convert_output_format_cartesian_to_polar(self, in_dict):\n",
    "        \n",
    "        out_dict = {}\n",
    "        for frame_cnt in in_dict.keys():\n",
    "            if frame_cnt not in out_dict:\n",
    "                out_dict[frame_cnt] = []\n",
    "                for tmp_val in in_dict[frame_cnt]:\n",
    "                    x, y, z = tmp_val[1], tmp_val[2], tmp_val[3]\n",
    "\n",
    "                    # in degrees\n",
    "                    azimuth = np.arctan2(y, x) * 180 / np.pi\n",
    "                    elevation = np.arctan2(z, np.sqrt(x**2 + y**2)) * 180 / np.pi\n",
    "                    r = np.sqrt(x**2 + y**2 + z**2)\n",
    "                    out_dict[frame_cnt].append([tmp_val[0], azimuth, elevation])\n",
    "        return out_dict\n",
    "\n",
    "    # ------------------------------- Misc public functions -------------------------------\n",
    "    def get_classes(self):\n",
    "        \n",
    "        return self._unique_classes\n",
    "\n",
    "    def get_normalized_feat_dir(self):\n",
    "        \n",
    "        return os.path.join(\n",
    "            self._feat_label_dir,\n",
    "            '{}_norm'.format(self._dataset_combination)\n",
    "        )\n",
    "\n",
    "    def get_unnormalized_feat_dir(self):\n",
    "        \n",
    "        return os.path.join(\n",
    "            self._feat_label_dir,\n",
    "            '{}'.format(self._dataset_combination)\n",
    "        )\n",
    "\n",
    "    def get_label_dir(self):\n",
    "        \n",
    "        if self._is_eval:\n",
    "            return None\n",
    "        else:\n",
    "            return os.path.join(\n",
    "                self._feat_label_dir, '{}_label'.format(self._dataset_combination)\n",
    "            )\n",
    "\n",
    "    def get_normalized_wts_file(self):\n",
    "        \n",
    "        return os.path.join(\n",
    "            self._feat_label_dir,\n",
    "            '{}_wts'.format(self._dataset)\n",
    "        )\n",
    "\n",
    "    def get_nb_channels(self):\n",
    "        \n",
    "        return self._nb_channels\n",
    "\n",
    "    def get_nb_classes(self):\n",
    "        \n",
    "        return len(self._unique_classes)\n",
    "\n",
    "    def nb_frames_1s(self):\n",
    "        \n",
    "        return self._nb_label_frames_1s\n",
    "\n",
    "    def get_hop_len_sec(self):\n",
    "       \n",
    "        return self._hop_len_s\n",
    "\n",
    "    def get_nb_frames(self):\n",
    "        \n",
    "        return self._max_label_frames\n",
    "\n",
    "    def get_nb_mel_bins(self):\n",
    "        \n",
    "        return self._nb_mel_bins\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "W3sXqVHxCSSN",
    "outputId": "999b8ec1-aa9f-4dbc-c0e8-c6036f558997"
   },
   "outputs": [],
   "source": [
    "# Extracts the features, labels, and normalizes the development and evaluation split features.\n",
    "if 'dev' in process_str:\n",
    "    # -------------- Extract features and labels for development set -----------------------------\n",
    "    dev_feat_cls = FeatureClass(is_eval=False)\n",
    "\n",
    "    # Extract features and normalize them\n",
    "    dev_feat_cls.extract_all_feature()\n",
    "    dev_feat_cls.preprocess_features()\n",
    "\n",
    "    # # Extract labels in regression mode\n",
    "    dev_feat_cls.extract_all_labels()\n",
    "\n",
    "    print(\"Development dataset extraction finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JcQImVZeTZoW",
    "outputId": "ce1de851-b164-4f5e-e53a-890ae0d3359f"
   },
   "outputs": [],
   "source": [
    "if 'eval' in process_str:\n",
    "    # -----------------------------Extract ONLY features for evaluation set-----------------------------\n",
    "    eval_feat_cls = FeatureClass(is_eval=True)\n",
    "\n",
    "    # Extract features and normalize them\n",
    "    eval_feat_cls.extract_all_feature()\n",
    "    eval_feat_cls.preprocess_features()\n",
    "    print(\"Evaluation dataset extraction finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Feature_Extraction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
